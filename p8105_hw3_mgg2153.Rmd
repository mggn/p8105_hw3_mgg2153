---
title: "p8105_hw3_mgg2153"
author: "mggn"
date: "10/7/2020"
output: github_document
---

## Problem 1, as discussed in class

```{r setup, include=FALSE}
library(tidyverse)
library(p8105.datasets)

knitr::opts_chunk$set(
	fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

```{r}
data("instacart")
```

This dataset contains `r nrow(instacart)` rows and ... columns. 

Observations are the level of items in orders by user. There are user / order variables -- user ID, order ID, order day, and order hour. There are also item variables -- name, aisle, department, and some numeric codes. 

How many aisles, and which are most items from?

```{r}
instacart %>% 
	count(aisle) %>% 
	arrange(desc(n))
```


Let's make a plot

```{r}
instacart %>% 
	count(aisle) %>% 
	filter(n > 10000) %>% 
	mutate(
		aisle = factor(aisle),
		aisle = fct_reorder(aisle, n)
	) %>% 
	ggplot(aes(x = aisle, y = n)) + 
	geom_point() + 
	theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1))
```


Let's make a table!!

```{r}
instacart %>% 
	filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
	group_by(aisle) %>% 
	count(product_name) %>% 
	mutate(rank = min_rank(desc(n))) %>% 
	filter(rank < 4) %>% 
	arrange(aisle, rank) %>% 
	knitr::kable()
```


Apples vs ice cream..

```{r}
instacart %>% 
	filter(product_name %in% c("Pink Lady Apples", "Coffee Ice Cream")) %>% 
	group_by(product_name, order_dow) %>% 
	summarize(mean_hour = mean(order_hour_of_day)) %>% 
	pivot_wider(
		names_from = order_dow,
		values_from = mean_hour
	)
```


### `summarise()` regrouping output by 'product_name' (override with `.groups` argument)

## Problem 2

Here we are uploading the accelerometers data and tidying it just a bit, including  
(1) cleaning names  (2) changing variable types  (3) creating a binary weekday variable

```{r accel_data}
accel_df = read_csv("./data/accel_data.csv") %>%
  janitor::clean_names() %>%
  mutate(
    day = as.factor(day),
    week = as.factor(week),
    weekday = if_else(day %in% c("Saturday", "Sunday"), "FALSE", "TRUE")
  ) %>%
  relocate(weekday) %>%
  pivot_longer(
    activity_1:activity_1440,
    names_to = "minute",
    names_prefix = "activity_",
    values_to = "acceleration_force"
  ) %>%
  mutate(
    minute = as.factor(minute),
    acceleration_force = as.numeric(acceleration_force)
  )
```


```{r two_parttwo}
accel_df %>%
group_by(day, week) %>%
summarize(activity_total = sum(acceleration_force)) %>%
pivot_wider(
names_from = day,
values_from = activity_total
)
```


## Problem 3

```{r load_ny_noaa}

data("ny_noaa")

ny_weather_df =
ny_noaa %>%
  janitor::clean_names() %>%
  mutate(
    tmin = as.numeric(tmin),
    tmax = as.numeric(tmax),
  ) %>%
  separate(date, into = c("year", "month", "day")) %>%
  mutate(
    month = month.abb[as.factor(month)],
    year = as.factor(year),
    day = as.factor(day),
    tmin = tmin/10,
    tmax = tmax/10,
    prcp = prcp/10
  )


```

Let's see what's going on with snowfall:
```{r}
ny_weather_df %>%
  count(month, year, snow)%>%
  group_by(month, year)
```

Using this sort of crude method, it appears that the most common frequent value for
snowfall in mm for nyc is 0. This actually makes sense because how many months of the year
is it actually cold enough to snow? Not that many (although with climate change who knows).

And now I shall attempt to make a two-panel plot, which I ***believe*** you need
the library patchwork for:

```{r}
library(patchwork)



```
